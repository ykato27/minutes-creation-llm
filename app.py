# app.py

import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO

# --- ãƒšãƒ¼ã‚¸è¨­å®šã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
st.set_page_config(page_title="åŠ›é‡ãƒãƒƒãƒ—CSVç”Ÿæˆãƒ„ãƒ¼ãƒ«", layout="centered")
st.title("ğŸ“Š åŠ›é‡ãƒãƒƒãƒ—CSVç”Ÿæˆãƒ„ãƒ¼ãƒ«")

# final_dfã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§åˆæœŸåŒ–
if 'final_df' not in st.session_state:
    st.session_state['final_df'] = pd.DataFrame()


# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•° (æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ç§»æ¤) ---
def split_competence_category(df):
    """åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã€Œï¼ã€ã§åˆ†å‰²ã—ã¦20åˆ—ã«å±•é–‹"""
    # NaNã‚’ä¸€æ™‚çš„ã«ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦splitã‚’é©ç”¨
    df['åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼'] = df['åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼'].astype(str).str.strip()
    split_data = df['åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼'].str.split('ï¼', expand=True)

    if split_data.shape[1] > 20:
        split_data = split_data.iloc[:, :20]

    split_data = split_data.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)
    split_data = split_data.replace('', np.nan)

    # 20åˆ—ã«æº€ãŸãªã„å ´åˆã€NaNã§åˆ—ã‚’åŸ‹ã‚ã‚‹
    for i in range(split_data.shape[1], 20):
        split_data[i] = np.nan

    split_data.columns = [f'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å  ###[competence_category_name_{i}]###' for i in range(1, 21)]

    # å…ƒã® df ã«çµåˆã™ã‚‹å‰ã«ã€å…ƒã® df ã«'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼'ã®ã‚«ãƒ©ãƒ ãŒæ®‹ã£ã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆColabç‰ˆã¨æŒ™å‹•ã‚’åˆã‚ã›ã‚‹ãŸã‚ï¼‰
    if 'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼' not in df.columns:
         df['åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼'] = split_data.apply(lambda row: "ï¼".join(row.dropna().astype(str)), axis=1)

    return pd.concat([df.reset_index(drop=True), split_data.reset_index(drop=True)], axis=1)


def build_category_path(df):
    """ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‹ã‚‰éšå±¤ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
    category_cols = [f'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å  ###[competence_category_name_{i}]###'
                     for i in range(1, 21)
                     if f'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å  ###[competence_category_name_{i}]###' in df.columns]

    df["category_path"] = df[category_cols].apply(
        lambda row: "ï¼".join([str(x).strip() for x in row if pd.notna(x)]), axis=1
    )

    return df, category_cols


def expand_with_skill_codes(df_output, df_competence, item_type_name, skill_code_col):
    """åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨åŠ›é‡ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆã—ã¦ãƒãƒƒãƒ—è¡Œã‚’ç”Ÿæˆ"""
    results = []
    
    # æ—¢å­˜ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ‘ã‚¹ã‚’å…ˆã«ä½œæˆï¼ˆdf_competenceã¯ã™ã§ã«ãƒ‘ã‚¹ã‚’æŒã£ã¦ã„ã‚‹å‰æï¼‰

    for _, comp_row in df_competence.iterrows():
        comp_path = comp_row["category_path"]

        # åŠ›é‡ã‚«ãƒ†ã‚´ãƒªè¡Œã‚’è¿½åŠ 
        category_row_dict = {"ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—  ###[item_type]###": "CATEGORY_IN_MAP"}

        for i in range(1, 21):
            old_col = f'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å  ###[competence_category_name_{i}]###'
            new_col = f'åŠ›é‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªåï¼‰{i}  ###[item_code_{i:02d}]###'
            category_row_dict[new_col] = comp_row.get(old_col, np.nan)

        results.append(category_row_dict)

        # ãƒãƒƒãƒã™ã‚‹åŠ›é‡ã‚³ãƒ¼ãƒ‰è¡Œã‚’è¿½åŠ 
        matched_rows = df_output[df_output["category_path"] == comp_path]

        for _, out_row in matched_rows.iterrows():
            skill_row_dict = {"ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—  ###[item_type]###": item_type_name}

            # ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‚’ã‚³ãƒ”ãƒ¼
            for i in range(1, 21):
                old_col = f'åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ¼å  ###[competence_category_name_{i}]###'
                new_col = f'åŠ›é‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªåï¼‰{i}  ###[item_code_{i:02d}]###'

                val = comp_row.get(old_col)
                skill_row_dict[new_col] = val if pd.notna(val) else np.nan

            # å·¦ã‹ã‚‰é †ã«æ¢ã—ã¦æœ€åˆã®NULLã«åŠ›é‡ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥
            for i in range(1, 21):
                new_col = f'åŠ›é‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªåï¼‰{i}  ###[item_code_{i:02d}]###'
                if pd.isna(skill_row_dict[new_col]):
                    skill_row_dict[new_col] = out_row[skill_code_col]
                    break

            results.append(skill_row_dict)

    df_result = pd.DataFrame(results)

    # ã‚«ãƒ©ãƒ ã®é †åºã‚’æ•´ç†
    item_type_col = "ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—  ###[item_type]###"
    item_code_cols = [f'åŠ›é‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªåï¼‰{i}  ###[item_code_{i:02d}]###' for i in range(1, 21)]
    cols = [item_type_col] + item_code_cols
    cols = [c for c in cols if c in df_result.columns]

    return df_result[cols]


def process_skill_file(file_content, df_competence, item_type_name, skill_code_col):
    """ã‚¹ã‚­ãƒ«/æ•™è‚²/è³‡æ ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒãƒƒãƒ—è¡Œã‚’ç”Ÿæˆ"""
    # Streamlitã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã¯BytesIOãƒ©ã‚¤ã‚¯ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™ãŸã‚ã€ãã®ã¾ã¾ä½¿ç”¨
    df_skill = pd.read_csv(file_content)
    df_skill = split_competence_category(df_skill)
    df_skill, _ = build_category_path(df_skill)
    
    # df_competenceã‚‚å‡¦ç†ãŒå¿…è¦
    df_competence_copy = df_competence.copy()
    df_competence_copy = split_competence_category(df_competence_copy)
    df_competence_copy, _ = build_category_path(df_competence_copy)

    return expand_with_skill_codes(df_skill, df_competence_copy, item_type_name, skill_code_col)


# --- UI: ã‚¹ãƒ†ãƒƒãƒ—1: åŠ›é‡ãƒãƒƒãƒ—æƒ…å ±ã‚’å…¥åŠ› ---
st.header("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: åŠ›é‡ãƒãƒƒãƒ—æƒ…å ±ã‚’å…¥åŠ›")

col1, col2 = st.columns(2)
with col1:
    ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ = st.text_input("ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "11_ãƒ‡ãƒ¢_è¨­å‚™éƒ¨")
    åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰ = st.text_input("åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰", "GuRdXPEmx6y5EqcMeyKA")
with col2:
    åŠ›é‡ãƒãƒƒãƒ—å = st.text_input("åŠ›é‡ãƒãƒƒãƒ—å", "ãƒ‡ãƒ¢_åŠ›é‡ãƒãƒƒãƒ—")
    ãƒ•ã‚©ãƒ«ãƒ€å = st.text_input("ãƒ•ã‚©ãƒ«ãƒ€å", "")


# --- UI: ã‚¹ãƒ†ãƒƒãƒ—2: åŠ›é‡ã‚«ãƒ†ã‚´ãƒªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
st.header("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—2: åŠ›é‡ã‚«ãƒ†ã‚´ãƒªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (å¿…é ˆ)")
uploaded_competence = st.file_uploader(
    "competence_category.csvã‚’é¸æŠ", 
    type=["csv"], 
    key="comp_uploader"
)


# --- UI: ã‚¹ãƒ†ãƒƒãƒ—3: åŠ›é‡CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
st.header("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—3: åŠ›é‡CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã„ãšã‚Œã‹1ã¤ä»¥ä¸Šå¿…é ˆ)")

uploaded_skill = st.file_uploader("åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«ï¼‰CSV", type=["csv"], key="skill_uploader")
uploaded_education = st.file_uploader("åŠ›é‡ï¼ˆæ•™è‚²ï¼‰CSV", type=["csv"], key="edu_uploader")
uploaded_license = st.file_uploader("åŠ›é‡ï¼ˆè³‡æ ¼ï¼‰CSV", type=["csv"], key="lic_uploader")

# --- UI: ã‚¹ãƒ†ãƒƒãƒ—4: å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
st.markdown("---")
if st.button("âš™ï¸ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œ", type="primary"):
    # å¿…é ˆå…¥åŠ›ãƒã‚§ãƒƒã‚¯
    if not all([ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ.strip(), åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰.strip(), åŠ›é‡ãƒãƒƒãƒ—å.strip(), uploaded_competence]):
        st.error("âŒ ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰ã€åŠ›é‡ãƒãƒƒãƒ—åã€ãŠã‚ˆã³åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯å¿…é ˆã§ã™ã€‚")
        st.stop()
        
    uploaded_files = {
        'skill': uploaded_skill,
        'education': uploaded_education,
        'license': uploaded_license
    }
    if all(f is None for f in uploaded_files.values()):
        st.error("âŒ åŠ›é‡ï¼ˆã‚¹ã‚­ãƒ«/æ•™è‚²/è³‡æ ¼ï¼‰ã®ã„ãšã‚Œã‹1ã¤ä»¥ä¸Šã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ”ãƒŠãƒ¼è¡¨ç¤º
    with st.spinner('â³ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...'):
        try:
            # åŠ›é‡ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            df_competence = pd.read_csv(uploaded_competence)

            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            all_results = []
            file_configs = [
                ('skill', "SKILL", "åŠ›é‡ã‚³ãƒ¼ãƒ‰  ###[skill_code]###"),
                ('education', "EDUCATION", "åŠ›é‡ã‚³ãƒ¼ãƒ‰  ###[education_code]###"),
                ('license', "LICENSE", "åŠ›é‡ã‚³ãƒ¼ãƒ‰  ###[license_code]###")
            ]

            for file_key, item_type, code_col in file_configs:
                file_content = uploaded_files[file_key]
                if file_content is not None:
                    df_result = process_skill_file(file_content, df_competence, item_type, code_col)
                    all_results.append(df_result)
                else:
                    st.info(f"âŠ˜ {item_type}ãƒ•ã‚¡ã‚¤ãƒ«: ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰")

            # çµæœã‚’çµ±åˆ
            if not all_results:
                st.error("å‡¦ç†ã™ã‚‹åŠ›é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.stop()

            final_df = pd.concat(all_results, ignore_index=True)

            # --- æ—¢å­˜ã®ã‚½ãƒ¼ãƒˆã¨é‡è¤‡å‰Šé™¤ãƒ­ã‚¸ãƒƒã‚¯ ---
            item_code_cols = [f'åŠ›é‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ†ã‚´ãƒªåï¼‰{i}  ###[item_code_{i:02d}]###' for i in range(1, 21)]

            def get_category_path(row):
                path_parts = []
                for col in item_code_cols:
                    if col in row.index and pd.notna(row[col]) and str(row[col]).strip():
                        path_parts.append(str(row[col]).strip())
                return "ï¼".join(path_parts)

            final_df["_sort_path"] = final_df.apply(get_category_path, axis=1)
            item_type_order = {"CATEGORY_IN_MAP": 0, "SKILL": 1, "EDUCATION": 2, "LICENSE": 3}
            final_df["_item_type_order"] = final_df["ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—  ###[item_type]###"].map(lambda x: item_type_order.get(x, 99))
            final_df = final_df.sort_values(by=["_sort_path", "_item_type_order"], ascending=[True, True]).reset_index(drop=True)

            # é‡è¤‡ã™ã‚‹CATEGORY_IN_MAPè¡Œã‚’å‰Šé™¤
            seen_category_paths = set()
            rows_to_keep = []
            for idx, row in final_df.iterrows():
                if row["ã‚¢ã‚¤ãƒ†ãƒ ã‚¿ã‚¤ãƒ—  ###[item_type]###"] == "CATEGORY_IN_MAP":
                    category_path = row["_sort_path"]
                    if category_path not in seen_category_paths:
                        seen_category_paths.add(category_path)
                        rows_to_keep.append(idx)
                else:
                    rows_to_keep.append(idx)
            
            final_df = final_df.loc[rows_to_keep].reset_index(drop=True)
            final_df = final_df.drop(columns=["_sort_path", "_item_type_order"])

            # --- è¿½åŠ ã‚«ãƒ©ãƒ ã®è¨­å®š ---
            additional_cols = [
                "ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  ###[principal_project_name]###",
                "åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰  ###[competence_map_code]###",
                "åŠ›é‡ãƒãƒƒãƒ—å",
                "ãƒ•ã‚©ãƒ«ãƒ€å",
                "å¿…è¦ãƒ¬ãƒ™ãƒ«(ä»¥ä¸Š)  ###[required_competence_level_label]###",
                "å¿…è¦äººæ•°  ###[required_head_count]###"
            ]
            for col in additional_cols:
                if col not in final_df.columns:
                    final_df[col] = ""

            final_df["ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  ###[principal_project_name]###"] = ä¸»ç®¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ.strip()
            final_df["åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰  ###[competence_map_code]###"] = åŠ›é‡ãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ‰.strip()
            final_df["åŠ›é‡ãƒãƒƒãƒ—å"] = åŠ›é‡ãƒãƒƒãƒ—å.strip()
            final_df["ãƒ•ã‚©ãƒ«ãƒ€å"] = ãƒ•ã‚©ãƒ«ãƒ€å.strip()

            final_df = final_df[additional_cols + [c for c in final_df.columns if c not in additional_cols]]
            
            # å‡¦ç†çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state['final_df'] = final_df
            
            st.success(f"âœ… å‡¦ç†å®Œäº†ï¼æœ€çµ‚çµæœ: {len(final_df)}è¡Œ")

        except Exception as e:
            st.error(f"âš ï¸ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.exception(e)


# --- çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¡¨ç¤º ---
st.markdown("---")
if not st.session_state['final_df'].empty:
    st.subheader("ğŸ“¥ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    # CSVã«å¤‰æ›ï¼ˆBytesIOã‚’ä½¿ç”¨ã™ã‚‹ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¯€ç´„ã§ãã‚‹ï¼‰
    csv_buffer = BytesIO()
    st.session_state['final_df'].to_csv(csv_buffer, index=False, encoding="utf-8-sig")
    csv_data = csv_buffer.getvalue()

    st.download_button(
        label="ğŸš€ competence_map_related_item_for_map.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name="competence_map_related_item_for_map.csv",
        mime="text/csv"
    )

    st.subheader("ğŸ“‘ çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…ˆé ­5è¡Œ)")
    st.dataframe(st.session_state['final_df'].head())